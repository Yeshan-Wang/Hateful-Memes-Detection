{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a728816-8439-4744-b0ef-f71834902406",
        "outputId": "a10556dc-9868-4a25-db97-8c47a87be301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 10 02:42:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ],
      "id": "3a728816-8439-4744-b0ef-f71834902406"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff84dfc3-14b3-4e9c-a84e-45d220bc57d6",
        "outputId": "f4e03f31-2913-4471-848b-f982ed3a8c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! unzip -q '/content/drive/MyDrive/hateful_memes.zip' -d '/content/data'"
      ],
      "id": "ff84dfc3-14b3-4e9c-a84e-45d220bc57d6"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcd350b4-79f8-4b8b-8d27-e58893fca8f5",
        "outputId": "dd14399c-0afd-473b-c079-ba235449675f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install --quiet augly[text]\n",
        "! pip install --quiet ftfy regex tqdm\n",
        "! pip install --quiet git+https://github.com/openai/CLIP.git"
      ],
      "id": "fcd350b4-79f8-4b8b-8d27-e58893fca8f5"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f7588592-aa07-4e30-814b-adf3f7094b4b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.image as img\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR, LinearLR, CosineAnnealingLR\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms as T\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import cv2\n",
        "import clip\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import augly.text as textaugs\n",
        "import random"
      ],
      "id": "f7588592-aa07-4e30-814b-adf3f7094b4b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ishr5BVmbVAR"
      },
      "source": [
        "## 1. Text Augmentation"
      ],
      "id": "Ishr5BVmbVAR"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5VEyRmJcbEpi"
      },
      "outputs": [],
      "source": [
        "initial_train = pd.read_json('/content/data/hateful_memes/train.jsonl', lines=True)\n",
        "num_alter = len(initial_train)\n",
        "random.seed(0)\n",
        "random_sample = random.sample(range(0, num_alter), num_alter//2)\n",
        "aug = textaugs.ReplaceSimilarUnicodeChars(aug_word_p=0.8)\n",
        "\n",
        "# Replace some characters of original meme texts with similar characters that do not alter semantic\n",
        "for i in random_sample:\n",
        "    meta = []\n",
        "    replaced_text = aug(initial_train['text'][i], metadata=meta)\n",
        "    df = pd.DataFrame([[initial_train['id'][i], initial_train['img'][i], initial_train['label'][i], replaced_text]],\n",
        "                      columns=['id','img','label','text'])\n",
        "    initial_train = pd.concat([initial_train, df], ignore_index=True)"
      ],
      "id": "5VEyRmJcbEpi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Original Text vs Augmented Text\n",
        "index = random_sample[0]\n",
        "initial_train[initial_train['id'] == initial_train['id'][index]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "FgdWszAi97mC",
        "outputId": "9531c194-c0f3-40c7-eabf-43dcb8a964cb"
      },
      "id": "FgdWszAi97mC",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id            img  label                                        text\n",
              "6311  18362  img/18362.png      0  if they don't like it here they can leave!\n",
              "8500  18362  img/18362.png      0  Ίf Ŧhey don't lίke Īt her£ τhey caŉ leavĖ!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65a03fae-c236-44b8-a79f-254749cc76ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6311</th>\n",
              "      <td>18362</td>\n",
              "      <td>img/18362.png</td>\n",
              "      <td>0</td>\n",
              "      <td>if they don't like it here they can leave!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8500</th>\n",
              "      <td>18362</td>\n",
              "      <td>img/18362.png</td>\n",
              "      <td>0</td>\n",
              "      <td>Ίf Ŧhey don't lίke Īt her£ τhey caŉ leavĖ!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65a03fae-c236-44b8-a79f-254749cc76ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65a03fae-c236-44b8-a79f-254749cc76ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65a03fae-c236-44b8-a79f-254749cc76ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bt_HbxeFbfIl"
      },
      "outputs": [],
      "source": [
        "# save as augmented training set\n",
        "initial_train.to_json('/content/data/hateful_memes/augment_train.jsonl', orient='records', lines=True)"
      ],
      "id": "Bt_HbxeFbfIl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8c9bb2-0949-422c-9d30-7069ad357881"
      },
      "source": [
        "## 2. Load dataset"
      ],
      "id": "7a8c9bb2-0949-422c-9d30-7069ad357881"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CcaiFYZFpTj9"
      },
      "outputs": [],
      "source": [
        "class ScaleMaxSideToSize(object):\n",
        "  def __init__(self, size):\n",
        "    self.size = size\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    sample = cv2.resize(sample, (self.size, self.size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return sample\n",
        "\n",
        "\n",
        "class CropCenter(object):\n",
        "  def __init__(self, size):\n",
        "    self.size = size\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    img = sample\n",
        "    h, w, _ = img.shape\n",
        "    margin_h = (h - self.size) // 2\n",
        "    margin_w = (w - self.size) // 2\n",
        "    sample = img[margin_h:margin_h + self.size, margin_w:margin_w + self.size]\n",
        "\n",
        "    return sample"
      ],
      "id": "CcaiFYZFpTj9"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c106a57e-b40b-4769-8b23-3c55d76092c3"
      },
      "outputs": [],
      "source": [
        "class Load_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_path, transforms):\n",
        "    self.data = [json.loads(l) for l in open(data_path)]\n",
        "    self.data_dir = os.path.dirname(data_path)\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    path = os.path.join(self.data_dir, self.data[index][\"img\"])\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    text = self.data[index][\"text\"]\n",
        "    label = self.data[index][\"label\"]\n",
        "\n",
        "    if self.transforms is not None:\n",
        "        image = self.transforms(image)\n",
        "\n",
        "    return image, text, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "id": "c106a57e-b40b-4769-8b23-3c55d76092c3"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dd0066bd-8704-4da6-a3b7-20b93ce65864"
      },
      "outputs": [],
      "source": [
        "CROP_SIZE = 336\n",
        "MEAN = torch.tensor([0.485, 0.456, 0.406])\n",
        "STD = torch.tensor([0.229, 0.224, 0.225])\n",
        "\n",
        "transforms = T.Compose([\n",
        "    ScaleMaxSideToSize(CROP_SIZE),\n",
        "    CropCenter(CROP_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=MEAN, std=STD)])\n",
        "\n",
        "\n",
        "train_path = '/content/data/hateful_memes/augment_train.jsonl'\n",
        "train_dataset = Load_Dataset(train_path, transforms)\n",
        "\n",
        "dev_path = '/content/data/hateful_memes/dev_seen.jsonl'\n",
        "dev_dataset = Load_Dataset(dev_path, transforms)\n",
        "\n",
        "test_path = '/content/data/hateful_memes/test_seen.jsonl'\n",
        "test_dataset = Load_Dataset(test_path, transforms)"
      ],
      "id": "dd0066bd-8704-4da6-a3b7-20b93ce65864"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4b17f6-8ed7-4d2f-bcef-264d36e4acbf"
      },
      "source": [
        "## 3. Use CLIP to encode each modality to get image and text features"
      ],
      "id": "ce4b17f6-8ed7-4d2f-bcef-264d36e4acbf"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1af2651d-6f91-4eaf-8e67-5c0b55818a49",
        "outputId": "53ec7d67-c06c-40ba-f8cf-a41151efb0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 891M/891M [00:26<00:00, 34.8MiB/s]\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CLIP_model, preprocess = clip.load('ViT-L/14@336px', device=device)"
      ],
      "id": "1af2651d-6f91-4eaf-8e67-5c0b55818a49"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc1a8ce-457e-4d75-8524-75f4612d84ad",
        "outputId": "b27683cb-5835-4df3-812d-6b36ab41f94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 128/128 [04:01<00:00,  1.89s/it]\n",
            "100%|██████████| 5/5 [00:09<00:00,  1.91s/it]\n",
            "100%|██████████| 10/10 [00:18<00:00,  1.87s/it]\n"
          ]
        }
      ],
      "source": [
        "def encode_features(model, dataset):\n",
        "  all_features = []\n",
        "  all_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, texts, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
        "      image_input = torch.tensor(np.stack(images)).to(device)\n",
        "      text_tokens = clip.tokenize([desc[:77] for desc in texts]).to(device)\n",
        "\n",
        "      image_features = model.encode_image(image_input).type(torch.float).to(device)\n",
        "      text_features = model.encode_text(text_tokens).type(torch.float).to(device)\n",
        "\n",
        "      features = torch.cat([image_features, text_features], dim=1)\n",
        "\n",
        "      all_features.extend(features)\n",
        "      all_labels.extend(labels)\n",
        "\n",
        "  return all_features, all_labels\n",
        "\n",
        "\n",
        "# Use CLIP to encode each modality to get image & text features\n",
        "features_train, labels_train = encode_features(CLIP_model, train_dataset)\n",
        "features_dev, labels_dev = encode_features(CLIP_model, dev_dataset)\n",
        "features_test, labels_test = encode_features(CLIP_model, test_dataset)"
      ],
      "id": "7cc1a8ce-457e-4d75-8524-75f4612d84ad"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "399d9c37-8491-4788-aadc-256b32910391"
      },
      "outputs": [],
      "source": [
        "class DefineDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    return self.features[index], self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "\n",
        "# Define train/dev/test set using image & text features and gold labels\n",
        "train_set = DefineDataset(features_train, labels_train)\n",
        "dev_set = DefineDataset(features_dev, labels_dev)\n",
        "test_set = DefineDataset(features_test, labels_test)"
      ],
      "id": "399d9c37-8491-4788-aadc-256b32910391"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e07bb92-4639-433e-a984-84170c85b9b8"
      },
      "source": [
        "## 4. Hhyper-parameters tuning for learning rate, batch size, scheduler type, and save all best performing models based on the validation AUROC score"
      ],
      "id": "5e07bb92-4639-433e-a984-84170c85b9b8"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f4668dcc-54b2-4036-861b-2fe3849841fb"
      },
      "outputs": [],
      "source": [
        "def compute_auroc(model, loader):\n",
        "  \"\"\"\n",
        "  Compute AUROC on the dataset wrapped in a loader\n",
        "  Return: AUROC score as a float value between 0 and 1\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  real_labels = []\n",
        "  probabilities = []\n",
        "\n",
        "  for i_step, (x, y) in enumerate(loader):\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    prediction = model(x)\n",
        "    # select probabilities corresponding to the positive class\n",
        "    prediction = prediction[:, 1]  # positive class in the second column\n",
        "    probabilities.extend(prediction.detach().cpu().numpy())\n",
        "    real_labels.extend(y.detach().cpu().numpy())\n",
        "\n",
        "  auroc = roc_auc_score(real_labels, probabilities)*100\n",
        "\n",
        "  return auroc"
      ],
      "id": "f4668dcc-54b2-4036-861b-2fe3849841fb"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7700aaa-c37c-4b18-a30b-8e1df1653d51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc8057a-e0e1-4bb9-f5dd-d66e62c21247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model: Epoch_18_of_50_Learning_rate_0.01_Batch_size_500_Scheduler_LinearLR.ckpt  Validation AUROC: 81.15\n",
            "Saved Model: Epoch_20_of_50_Learning_rate_0.01_Batch_size_500_Scheduler_CosineAnnealingLR.ckpt  Validation AUROC: 81.25\n",
            "Saved Model: Epoch_25_of_50_Learning_rate_0.01_Batch_size_900_Scheduler_LinearLR.ckpt  Validation AUROC: 81.52\n"
          ]
        }
      ],
      "source": [
        "input_shape = features_train[0].shape[0]\n",
        "num_classes = 2\n",
        "torch.manual_seed(515)\n",
        "shape = 256\n",
        "\n",
        "# Define hyperparameters\n",
        "maximum_epochs = [50, 100]\n",
        "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]\n",
        "batch_sizes = [500, 900]\n",
        "schedulers = ['StepLR', 'LinearLR', 'CosineAnnealingLR']\n",
        "top_val_AUROC = 81.03\n",
        "\n",
        "best_models = []\n",
        "\n",
        "for epochs in maximum_epochs:\n",
        "  for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "      for sched in schedulers:\n",
        "        # Construct a neural network for classification\n",
        "        nn_model = nn.Sequential(\n",
        "            nn.Linear(input_shape, shape),\n",
        "            nn.Dropout(0.66),\n",
        "            nn.BatchNorm1d(shape),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(shape, shape),\n",
        "            nn.Dropout(0.66),\n",
        "            nn.BatchNorm1d(shape),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(shape, num_classes),)\n",
        "\n",
        "        nn_model = nn_model.to(device)\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(nn_model.parameters(), lr=lr)\n",
        "\n",
        "        if sched == 'StepLR':\n",
        "          scheduler = StepLR(optimizer, step_size=10, gamma=0.8)\n",
        "        if sched == 'LinearLR':\n",
        "          scheduler = LinearLR(optimizer)\n",
        "        if sched == 'CosineAnnealingLR':\n",
        "          scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "        train_loader = DataLoader(train_set, batch_size=bs)\n",
        "        val_loader = DataLoader(dev_set, batch_size=bs)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "          nn_model.train()\n",
        "          loss_accum = 0\n",
        "          for i_step, (x, y) in enumerate(train_loader):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            prediction = nn_model(x)\n",
        "            loss_value = loss(prediction, y.type(torch.long))\n",
        "            optimizer.zero_grad()\n",
        "            loss_value.backward()\n",
        "            optimizer.step()\n",
        "            loss_accum += loss_value\n",
        "\n",
        "          ave_loss = loss_accum / (i_step + 1)\n",
        "          val_AUROC = compute_auroc(nn_model, val_loader)\n",
        "          if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "          # Save the best models based on validation AUROC\n",
        "          if val_AUROC > top_val_AUROC:\n",
        "            top_val_AUROC = val_AUROC\n",
        "            m_name = f'Epoch_{epoch}_of_{epochs}_Learning_rate_{lr}_Batch_size_{bs}_Scheduler_{sched}.ckpt'\n",
        "            torch.save(nn_model, open(m_name, 'wb'))\n",
        "            best_models.append(m_name)\n",
        "            print('Saved Model:', m_name, ' Validation AUROC:', round(val_AUROC, 2))"
      ],
      "id": "b7700aaa-c37c-4b18-a30b-8e1df1653d51"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdaa3cd1-3201-48fa-b00a-084d5807557a"
      },
      "source": [
        "## 5. Perform soft voting method for ensemble learning by averaging the predictions of best performing models"
      ],
      "id": "bdaa3cd1-3201-48fa-b00a-084d5807557a"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtDtcz4VyhOS",
        "outputId": "776614a7-524b-4b5b-819b-f055d0a542f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUROC: 82.06\n"
          ]
        }
      ],
      "source": [
        "val_all_predictions = []\n",
        "\n",
        "for best_model_name in best_models:\n",
        "    best_model = torch.load(open(best_model_name, 'rb'))\n",
        "    best_model = best_model.to(device)\n",
        "    best_model.eval()\n",
        "\n",
        "    val_loader = DataLoader(dev_set, batch_size=500)\n",
        "    val_real_labels = []\n",
        "    val_predictions = []\n",
        "\n",
        "    for i_step, (x, y) in enumerate(val_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        prediction = best_model(x)\n",
        "        # select probabilities corresponding to the positive class\n",
        "        prediction = prediction[:, 1]  # positive class in the second column\n",
        "        val_predictions.extend(prediction.detach().cpu().numpy())\n",
        "        val_real_labels.extend(y.detach().cpu().numpy())\n",
        "\n",
        "    # append predictions to all_predictions\n",
        "    val_all_predictions.append(val_predictions)\n",
        "\n",
        "# convert list to numpy arrays for easier manipulation\n",
        "val_all_predictions = np.array(val_all_predictions)\n",
        "\n",
        "# perform soft voting by taking the average predicted probabilities\n",
        "val_final_predictions = val_all_predictions.mean(axis=0)\n",
        "\n",
        "# compute and print the AUROC for the final prediction\n",
        "val_auroc_score = roc_auc_score(val_real_labels, val_final_predictions)*100\n",
        "print('Validation AUROC:', round(val_auroc_score, 2))"
      ],
      "id": "GtDtcz4VyhOS"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "802772c4-772d-4df6-8b15-c7c6e6e348c9",
        "outputId": "d64a4d18-91da-44f2-caee-88e042d478c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test AUROC: 84.86\n"
          ]
        }
      ],
      "source": [
        "test_all_predictions = []\n",
        "\n",
        "for best_model_name in best_models:\n",
        "    best_model = torch.load(open(best_model_name, 'rb'))\n",
        "    best_model = best_model.to(device)\n",
        "    best_model.eval()\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=500)\n",
        "    test_real_labels = []\n",
        "    test_predictions = []\n",
        "\n",
        "    for i_step, (x, y) in enumerate(test_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        prediction = best_model(x)\n",
        "        # select probabilities corresponding to the positive class\n",
        "        prediction = prediction[:, 1]  # positive class in the second column\n",
        "        test_predictions.extend(prediction.detach().cpu().numpy())\n",
        "        test_real_labels.extend(y.detach().cpu().numpy())\n",
        "\n",
        "    # append predictions to all_predictions\n",
        "    test_all_predictions.append(test_predictions)\n",
        "\n",
        "# convert list to numpy arrays for easier manipulation\n",
        "test_all_predictions = np.array(test_all_predictions)\n",
        "\n",
        "# perform soft voting by taking the average predicted probabilities\n",
        "test_final_predictions = test_all_predictions.mean(axis=0)\n",
        "\n",
        "# compute and print the AUROC for the final prediction\n",
        "test_auroc_score = roc_auc_score(test_real_labels, test_final_predictions)*100\n",
        "print('Test AUROC:', round(test_auroc_score, 2))"
      ],
      "id": "802772c4-772d-4df6-8b15-c7c6e6e348c9"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}